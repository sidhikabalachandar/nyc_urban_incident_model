{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out correlation and rmse results for predicted P(T) and predicted ratings for real data for full model, reports only model, and ratings only model\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Set the font used for math expressions to LaTeX\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc615b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "base_file = '/share/garg/311_data/sb2377/clean_codebase/three_year_base.csv'\n",
    "type_rating_observed_base_file = '/share/garg/311_data/sb2377/clean_codebase/three_year_type_rating_observed_base.csv'\n",
    "results_dir = '/share/garg/311_data/sb2377/results'\n",
    "demographics_file = '/share/garg/311_data/sb2377/clean_codebase/tract_demographics.csv'\n",
    "\n",
    "# user specified arguments\n",
    "types = {'Street': 'StreetConditionDOT',\n",
    "         'Park': 'MaintenanceorFacilityDPR',\n",
    "         'Rodent': 'RodentDOHMH',\n",
    "         'Food': 'FoodDOHMH',\n",
    "         'DCWP': 'ConsumerComplaintDCWP'}\n",
    "models = {'Full model': {'job_ids':[3000] + [i * 3 + 3005 for i in range(12)]},\n",
    "          'Ratings-only model': {'job_ids':[3002] + [i * 3 + 3007 for i in range(12)]},\n",
    "          'Reports-only model': {'job_ids':[3001] + [i * 3 + 3006 for i in range(12)]}}\n",
    "epoch = '59'\n",
    "budget_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00d75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "base_df = pd.read_csv(base_file)\n",
    "type_rating_observed_base_df = pd.read_csv(type_rating_observed_base_file)\n",
    "demographics_df = pd.read_csv(demographics_file)\n",
    "base_node_df = base_df[['GEOID', 'node_idxs']].drop_duplicates()\n",
    "demographics_df = pd.merge(demographics_df, base_node_df, on='GEOID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff69a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get type indices\n",
    "# for df with all types\n",
    "type_df = base_df[['typeagency', 'type_idxs']].drop_duplicates()\n",
    "indices = {}\n",
    "for type_name, type_id in types.items():\n",
    "    idx = type_df[type_df['typeagency'] == type_id]['type_idxs'].iloc[0]\n",
    "    indices[type_name] = idx\n",
    "\n",
    "# for df with only types with observed ratings\n",
    "type_df = type_rating_observed_base_df[['typeagency', 'type_idxs']].drop_duplicates()\n",
    "type_rating_observed_indices = {}\n",
    "for type_name, type_id in types.items():\n",
    "    idx = type_df[type_df['typeagency'] == type_id]['type_idxs'].iloc[0]\n",
    "    type_rating_observed_indices[type_name] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274f4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(race_white_nh_pct):\n",
    "    \"\"\"\n",
    "    Create race group labels based on terciles of white non-Hispanic percentage.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    race_white_nh_pct : array-like\n",
    "        Array of percent white non-Hispanic for each census tract (0-100 scale)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    labels : numpy array of strings\n",
    "        Array of labels: 'predominantly_minority', 'mixed', or 'predominantly_white'\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    - Predominantly minority: Bottom 33% (lowest % white)\n",
    "    - Mixed/Diverse: Middle 33%\n",
    "    - Predominantly white: Top 33% (highest % white)\n",
    "    \"\"\"\n",
    "    race_white_nh_pct = np.array(race_white_nh_pct)\n",
    "    \n",
    "    # Calculate tercile thresholds (33rd and 67th percentiles)\n",
    "    p33 = np.percentile(race_white_nh_pct, 33.33)\n",
    "    p67 = np.percentile(race_white_nh_pct, 66.67)\n",
    "    \n",
    "    # Create labels\n",
    "    labels = np.empty(len(race_white_nh_pct), dtype=object)\n",
    "    labels[race_white_nh_pct < p33] = 0\n",
    "    labels[(race_white_nh_pct >= p33) & (race_white_nh_pct < p67)] = 1\n",
    "    labels[race_white_nh_pct >= p67] = 2\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7901a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model: checkpoint files done = 13\n",
      "Full model: results files done = 13\n",
      "Ratings-only model: checkpoint files done = 13\n",
      "Ratings-only model: results files done = 13\n",
      "Reports-only model: checkpoint files done = 13\n",
      "Reports-only model: results files done = 13\n"
     ]
    }
   ],
   "source": [
    "# get predicted ratings for all jobs for types with observed ratings\n",
    "checkpoint_file = '{}/job{}/model-epoch={}.ckpt'\n",
    "results_file = '{}/job{}/epoch={}_test.pkl'\n",
    "checkpoint_counters = {}\n",
    "results_counters = {}\n",
    "for m in models:\n",
    "    checkpoint_counters[m] = 0\n",
    "    results_counters[m] = 0\n",
    "type_rating_observed_dfs = {}\n",
    "for m in models:\n",
    "    type_rating_observed_dfs[m] = []\n",
    "\n",
    "for m in models:\n",
    "    for i, job_idx in enumerate(models[m]['job_ids']):\n",
    "        if os.path.exists(checkpoint_file.format(results_dir, job_idx, epoch)):\n",
    "            checkpoint_counters[m] += 1\n",
    "        if os.path.exists(results_file.format(results_dir, job_idx, epoch)):\n",
    "            results_counters[m] += 1\n",
    "            with open(results_file.format(results_dir, job_idx, epoch), 'rb') as file:\n",
    "                pred_rating, true_rating, mask, node_embedding, type_embedding, node_idxs, type_idxs, demographics, pred_pt, true_t = pickle.load(file)\n",
    "\n",
    "            raw_demographics_df = pd.DataFrame()\n",
    "            raw_demographics_df['node_idxs'] = node_idxs\n",
    "            raw_demographics_df = raw_demographics_df.merge(demographics_df, on='node_idxs', how='left')\n",
    "            \n",
    "            income_groups = create_groups(raw_demographics_df['income_median'].values)\n",
    "            race_groups = create_groups(raw_demographics_df['race_white_nh_pct'].values)\n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            df['pred_rating'] = pred_rating\n",
    "            df['true_rating'] = true_rating\n",
    "            df['node_idxs'] = node_idxs\n",
    "            df['type_idxs'] = type_idxs\n",
    "            df['pred_pt'] = pred_pt\n",
    "            df['true_t'] = true_t\n",
    "            df['mask'] = mask\n",
    "            df['income_groups'] = income_groups\n",
    "            df['race_groups'] = race_groups\n",
    "            df['income_median'] = raw_demographics_df['income_median'].values\n",
    "            df['race_white_nh_pct'] = raw_demographics_df['race_white_nh_pct'].values\n",
    "            df['population'] = raw_demographics_df['population'].values\n",
    "\n",
    "            type_rating_observed_dfs[m].append(df)\n",
    "\n",
    "for m in models:\n",
    "    print('{}: checkpoint files done = {}'.format(m, checkpoint_counters[m]))\n",
    "    print('{}: results files done = {}'.format(m, results_counters[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topk_coverage(true_ratings, predicted_ratings, k_values=[5, 10, 20, 50]):\n",
    "    \"\"\"\n",
    "    Evaluate top-k coverage for incident prediction.\n",
    "    \n",
    "    Args:\n",
    "        true_ratings: Ground truth ratings (lower = worse condition)\n",
    "        predicted_ratings: Model predicted ratings\n",
    "        k_values: List of k values to evaluate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of coverage scores for each k\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Get indices of k worst neighborhoods (lowest ratings)\n",
    "        true_topk = np.argsort(true_ratings)[:k]  # Lowest k ratings\n",
    "        pred_topk = np.argsort(predicted_ratings)[:k]\n",
    "        \n",
    "        # Calculate coverage: intersection / k\n",
    "        coverage = len(np.intersect1d(true_topk, pred_topk)) / k\n",
    "        results[f'top_{k}_coverage'] = coverage\n",
    "    \n",
    "    return results\n",
    "\n",
    "def expected_calibration_error(true_ratings, predicted_ratings, n_bins=10):\n",
    "    \"\"\"\n",
    "    Expected Calibration Error for continuous predictions.\n",
    "    \n",
    "    ECE = weighted average of |predicted - actual| across bins\n",
    "    Lower is better (0 = perfect calibration)\n",
    "    \"\"\"\n",
    "    bin_edges = np.percentile(predicted_ratings, \n",
    "                               np.linspace(0, 100, n_bins + 1))\n",
    "    \n",
    "    ece = 0.0\n",
    "    total_samples = len(predicted_ratings)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        in_bin = (predicted_ratings >= bin_edges[i]) & \\\n",
    "                 (predicted_ratings < bin_edges[i + 1])\n",
    "        \n",
    "        if in_bin.sum() > 0:\n",
    "            bin_weight = in_bin.sum() / total_samples\n",
    "            pred_mean = predicted_ratings[in_bin].mean()\n",
    "            true_mean = true_ratings[in_bin].mean()\n",
    "            \n",
    "            ece += bin_weight * abs(pred_mean - true_mean)\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def calculate_correlation_by_group(predictions, actuals, group_labels):\n",
    "    \"\"\"\n",
    "    Calculate correlation between predictions and actuals for each demographic group.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : array-like\n",
    "        Predicted values (e.g., predicted ratings)\n",
    "    actuals : array-like\n",
    "        Actual/ground truth values (e.g., true ratings)\n",
    "    group_labels : array-like\n",
    "        Demographic group labels for each observation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pandas DataFrame\n",
    "        DataFrame with correlation statistics for each group\n",
    "    \"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    group_labels = np.array(group_labels)\n",
    "    \n",
    "    # Calculate overall correlation\n",
    "    overall_corr = np.corrcoef(predictions, actuals)[0, 1]\n",
    "    \n",
    "    # Calculate correlation for each group\n",
    "    results = []\n",
    "    unique_groups = np.unique(group_labels)\n",
    "    \n",
    "    for group in unique_groups:\n",
    "        # Get data for this group\n",
    "        mask = group_labels == group\n",
    "        group_pred = predictions[mask]\n",
    "        group_actual = actuals[mask]\n",
    "        \n",
    "        # Calculate correlation\n",
    "        group_corr = np.corrcoef(group_pred, group_actual)[0, 1]\n",
    "        \n",
    "        # Calculate correlation gap (group - overall)\n",
    "        corr_gap = group_corr - overall_corr\n",
    "        \n",
    "        results.append({\n",
    "            'group': group,\n",
    "            'correlation_gap': corr_gap,\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def calculate_calibration_by_group(predicted_probs, actuals, group_labels):\n",
    "    \"\"\"\n",
    "    Calculate calibration error for each demographic group.\n",
    "    \n",
    "    Calibration measures whether predicted probabilities match empirical frequencies.\n",
    "    Expected Calibration Error (ECE) = |mean(predicted_probs) - mean(actuals)|\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predicted_probs : array-like\n",
    "        Predicted probabilities (e.g., P(report) from model)\n",
    "    actuals : array-like\n",
    "        Actual binary outcomes (e.g., 0/1 for whether report occurred)\n",
    "    group_labels : array-like\n",
    "        Demographic group labels for each observation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pandas DataFrame\n",
    "        DataFrame with calibration statistics for each group\n",
    "    \"\"\"\n",
    "    predicted_probs = np.array(predicted_probs)\n",
    "    actuals = np.array(actuals)\n",
    "    group_labels = np.array(group_labels)\n",
    "    \n",
    "    # Calculate overall calibration error\n",
    "    overall_mean_pred = np.mean(predicted_probs)\n",
    "    overall_mean_actual = np.mean(actuals)\n",
    "    overall_ece = np.abs(overall_mean_pred - overall_mean_actual)\n",
    "    \n",
    "    # Calculate calibration for each group\n",
    "    results = []\n",
    "    unique_groups = np.unique(group_labels)\n",
    "    \n",
    "    for group in unique_groups:\n",
    "        # Get data for this group\n",
    "        mask = group_labels == group\n",
    "        group_pred = predicted_probs[mask]\n",
    "        group_actual = actuals[mask]\n",
    "\n",
    "        # Mean predicted probability\n",
    "        mean_pred = np.mean(group_pred)\n",
    "        \n",
    "        # Empirical frequency (mean of binary actuals)\n",
    "        mean_actual = np.mean(group_actual)\n",
    "        \n",
    "        # Expected Calibration Error (ECE)\n",
    "        ece = np.abs(mean_pred - mean_actual)\n",
    "        \n",
    "        # Calibration gap (group ECE - overall ECE)\n",
    "        ece_gap = ece - overall_ece\n",
    "        \n",
    "        results.append({\n",
    "            'group': group,\n",
    "            'calibration_gap': ece_gap\n",
    "        })\n",
    "  \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def compute_representation_ratio(predicted_ratings, demographic_data, population, budget_k):\n",
    "    \"\"\"\n",
    "    Compute representation-based spatial equity using continuous demographic data (% white residents).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'predicted_rating': predicted_ratings,\n",
    "        'demographic_data': demographic_data,\n",
    "        'pop': population\n",
    "    })\n",
    "    \n",
    "    # Select tracts that receive the budget (lowest predicted ratings)\n",
    "    served_idx = np.argsort(df['predicted_rating'])[:budget_k]\n",
    "    df['served'] = False\n",
    "    df.loc[served_idx, 'served'] = True\n",
    "    \n",
    "    # Weighted average % white among served tracts\n",
    "    served_weighted = np.average(df[df['served']]['demographic_data'], weights=df[df['served']]['pop'])\n",
    "    \n",
    "    # Weighted average % white among all tracts\n",
    "    all_weighted = np.average(df['demographic_data'], weights=df['pop'])\n",
    "    \n",
    "    # Ratio: representation of white residents in served vs. total\n",
    "    representation_ratio = served_weighted / all_weighted \n",
    "    \n",
    "    return representation_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df1fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Full model, correlation: 0.5303 \\pm 0.0194\n",
      "Model: Full model, rmse: 0.5833 \\pm 0.0123\n",
      "Model: Full model, top_5_coverage: 0.1169 \\pm 0.0287\n",
      "Model: Full model, top_10_coverage: 0.1692 \\pm 0.0257\n",
      "Model: Full model, top_20_coverage: 0.2115 \\pm 0.0189\n",
      "Model: Full model, top_50_coverage: 0.2655 \\pm 0.0148\n",
      "Model: Full model, ece: 0.2072 \\pm 0.0080\n",
      "Model: Full model, Group number: 0, income_corr_gap: 0.0028 \\pm 0.0030\n",
      "Model: Full model, Group number: 1, income_corr_gap: -0.0023 \\pm 0.0028\n",
      "Model: Full model, Group number: 2, income_corr_gap: -0.0056 \\pm 0.0042\n",
      "Model: Full model, Group number: 0, race_corr_gap: -0.0005 \\pm 0.0043\n",
      "Model: Full model, Group number: 1, race_corr_gap: -0.0121 \\pm 0.0081\n",
      "Model: Full model, Group number: 2, race_corr_gap: -0.0006 \\pm 0.0048\n",
      "Model: Full model, Group number: 0, income_ece_gap: 0.0030 \\pm 0.0030\n",
      "Model: Full model, Group number: 1, income_ece_gap: -0.0012 \\pm 0.0049\n",
      "Model: Full model, Group number: 2, income_ece_gap: 0.0061 \\pm 0.0040\n",
      "Model: Full model, Group number: 0, race_ece_gap: 0.0006 \\pm 0.0041\n",
      "Model: Full model, Group number: 1, race_ece_gap: 0.0058 \\pm 0.0069\n",
      "Model: Full model, Group number: 2, race_ece_gap: 0.0083 \\pm 0.0059\n",
      "Model: Full model, income_representation_ratio: 0.8945 \\pm 0.0070\n",
      "Model: Full model, race_representation_ratio: 0.8451 \\pm 0.0155\n",
      "Model: Ratings-only model, correlation: 0.5223 \\pm 0.0185\n",
      "Model: Ratings-only model, rmse: 0.5852 \\pm 0.0116\n",
      "Model: Ratings-only model, top_5_coverage: 0.1262 \\pm 0.0232\n",
      "Model: Ratings-only model, top_10_coverage: 0.1692 \\pm 0.0253\n",
      "Model: Ratings-only model, top_20_coverage: 0.2046 \\pm 0.0203\n",
      "Model: Ratings-only model, top_50_coverage: 0.2655 \\pm 0.0164\n",
      "Model: Ratings-only model, ece: 0.2094 \\pm 0.0082\n",
      "Model: Ratings-only model, Group number: 0, income_corr_gap: 0.0056 \\pm 0.0046\n",
      "Model: Ratings-only model, Group number: 1, income_corr_gap: -0.0029 \\pm 0.0032\n",
      "Model: Ratings-only model, Group number: 2, income_corr_gap: -0.0099 \\pm 0.0074\n",
      "Model: Ratings-only model, Group number: 0, race_corr_gap: 0.0028 \\pm 0.0055\n",
      "Model: Ratings-only model, Group number: 1, race_corr_gap: -0.0193 \\pm 0.0082\n",
      "Model: Ratings-only model, Group number: 2, race_corr_gap: 0.0009 \\pm 0.0054\n",
      "Model: Ratings-only model, Group number: 0, income_ece_gap: 0.0036 \\pm 0.0044\n",
      "Model: Ratings-only model, Group number: 1, income_ece_gap: 0.0049 \\pm 0.0046\n",
      "Model: Ratings-only model, Group number: 2, income_ece_gap: 0.0022 \\pm 0.0048\n",
      "Model: Ratings-only model, Group number: 0, race_ece_gap: 0.0040 \\pm 0.0059\n",
      "Model: Ratings-only model, Group number: 1, race_ece_gap: 0.0124 \\pm 0.0056\n",
      "Model: Ratings-only model, Group number: 2, race_ece_gap: 0.0023 \\pm 0.0050\n",
      "Model: Ratings-only model, income_representation_ratio: 0.8956 \\pm 0.0079\n",
      "Model: Ratings-only model, race_representation_ratio: 0.8466 \\pm 0.0121\n",
      "Model: Reports-only model, correlation: -0.0904 \\pm 0.0271\n",
      "Model: Reports-only model, rmse: 0.6573 \\pm 0.0051\n",
      "Model: Reports-only model, top_5_coverage: 0.0123 \\pm 0.0137\n",
      "Model: Reports-only model, top_10_coverage: 0.0262 \\pm 0.0150\n",
      "Model: Reports-only model, top_20_coverage: 0.0354 \\pm 0.0069\n",
      "Model: Reports-only model, top_50_coverage: 0.0849 \\pm 0.0103\n",
      "Model: Reports-only model, ece: 0.1079 \\pm 0.0032\n",
      "Model: Reports-only model, Group number: 0, income_corr_gap: 0.0032 \\pm 0.0091\n",
      "Model: Reports-only model, Group number: 1, income_corr_gap: 0.0294 \\pm 0.0067\n",
      "Model: Reports-only model, Group number: 2, income_corr_gap: -0.0178 \\pm 0.0047\n",
      "Model: Reports-only model, Group number: 0, race_corr_gap: 0.0214 \\pm 0.0135\n",
      "Model: Reports-only model, Group number: 1, race_corr_gap: 0.0451 \\pm 0.0142\n",
      "Model: Reports-only model, Group number: 2, race_corr_gap: -0.0191 \\pm 0.0092\n",
      "Model: Reports-only model, Group number: 0, income_ece_gap: 0.0182 \\pm 0.0040\n",
      "Model: Reports-only model, Group number: 1, income_ece_gap: 0.0109 \\pm 0.0036\n",
      "Model: Reports-only model, Group number: 2, income_ece_gap: 0.0233 \\pm 0.0015\n",
      "Model: Reports-only model, Group number: 0, race_ece_gap: 0.0092 \\pm 0.0035\n",
      "Model: Reports-only model, Group number: 1, race_ece_gap: 0.0072 \\pm 0.0059\n",
      "Model: Reports-only model, Group number: 2, race_ece_gap: 0.0332 \\pm 0.0037\n",
      "Model: Reports-only model, income_representation_ratio: 1.1395 \\pm 0.0276\n",
      "Model: Reports-only model, race_representation_ratio: 1.1656 \\pm 0.0439\n"
     ]
    }
   ],
   "source": [
    "# print out correlation and rmse results for predicted ratings\n",
    "for m in models:\n",
    "    df_set = type_rating_observed_dfs[m]\n",
    "    metric_vals = {'correlation': [],\n",
    "               'rmse': [], \n",
    "               'top_5_coverage': [], \n",
    "               'top_10_coverage': [], \n",
    "               'top_20_coverage': [], \n",
    "               'top_50_coverage': [],\n",
    "               'ece': [],\n",
    "               'income_corr_gap': {0: [], 1: [], 2: []}, \n",
    "               'race_corr_gap': {0: [], 1: [], 2: []},\n",
    "               'income_ece_gap': {0: [], 1: [], 2: []},\n",
    "               'race_ece_gap': {0: [], 1: [], 2: []},\n",
    "               'income_representation_ratio': [],\n",
    "               'race_representation_ratio': []}\n",
    "    for t in types:\n",
    "        type_metric_vals = {'correlation': [],\n",
    "               'rmse': [], \n",
    "               'top_5_coverage': [], \n",
    "               'top_10_coverage': [], \n",
    "               'top_20_coverage': [], \n",
    "               'top_50_coverage': [],\n",
    "               'ece': [],\n",
    "               'income_corr_gap': {0: [], 1: [], 2: []}, \n",
    "               'race_corr_gap': {0: [], 1: [], 2: []},\n",
    "               'income_ece_gap': {0: [], 1: [], 2: []},\n",
    "               'race_ece_gap': {0: [], 1: [], 2: []},\n",
    "               'income_representation_ratio': [],\n",
    "               'race_representation_ratio': []}\n",
    "        idx = indices[t]\n",
    "        type_rating_observed_idx = type_rating_observed_indices[t]\n",
    "        for df in df_set:\n",
    "            df_type = df[df['type_idxs'] == idx]\n",
    "            if m == 'Ratings-only model':\n",
    "                df_type = df[df['type_idxs'] == type_rating_observed_idx]\n",
    "            else:\n",
    "                df_type = df[df['type_idxs'] == idx]\n",
    "            node_df = df_type.groupby(['node_idxs', 'type_idxs']).mean().reset_index()\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                if m == 'Reports-only model':\n",
    "                    # for reports-only model, we use -P(T) as a proxy for r\n",
    "                    pred_rating = -1 * node_df['pred_pt']\n",
    "                else:\n",
    "                    pred_rating = node_df['pred_rating']\n",
    "                # correlation\n",
    "                corr = pearsonr(node_df['pred_rating'], node_df['true_rating'])\n",
    "                type_metric_vals['correlation'].append(corr[0])\n",
    "                # rmse\n",
    "                rmse = np.sqrt(mean_squared_error(node_df['pred_rating'], node_df['true_rating']))\n",
    "                type_metric_vals['rmse'].append(rmse)\n",
    "                # top k coverage for predicted ratings\n",
    "                coverages = evaluate_topk_coverage(node_df['true_rating'], pred_rating)\n",
    "                for k in coverages:\n",
    "                    type_metric_vals[k].append(coverages[k])\n",
    "                # ECE\n",
    "                ece = expected_calibration_error(node_df['true_rating'], pred_rating)\n",
    "                type_metric_vals['ece'].append(ece)\n",
    "                # correlation gap\n",
    "                income_corr_gap = calculate_correlation_by_group(pred_rating, node_df['true_rating'], node_df['income_groups'])\n",
    "                race_corr_gap = calculate_correlation_by_group(pred_rating, node_df['true_rating'], node_df['race_groups'])\n",
    "                for i in range(3):\n",
    "                    type_metric_vals['income_corr_gap'][i].append(income_corr_gap[income_corr_gap['group'] == i]['correlation_gap'].item())\n",
    "                    type_metric_vals['race_corr_gap'][i].append(race_corr_gap[race_corr_gap['group'] == i]['correlation_gap'].item())\n",
    "                # ECE gap\n",
    "                income_ece_gap = calculate_calibration_by_group(pred_rating, node_df['true_rating'], node_df['income_groups'])\n",
    "                race_ece_gap = calculate_calibration_by_group(pred_rating, node_df['true_rating'], node_df['race_groups'])\n",
    "                for i in range(3):\n",
    "                    type_metric_vals['income_ece_gap'][i].append(income_ece_gap[income_ece_gap['group'] == i]['calibration_gap'].item())\n",
    "                    type_metric_vals['race_ece_gap'][i].append(race_ece_gap[race_ece_gap['group'] == i]['calibration_gap'].item())\n",
    "                # representation ratio\n",
    "                income_representation_ratio = compute_representation_ratio(pred_rating, node_df['income_median'], node_df['population'], budget_k)\n",
    "                race_representation_ratio = compute_representation_ratio(pred_rating, node_df['race_white_nh_pct'], node_df['population'], budget_k)\n",
    "                type_metric_vals['income_representation_ratio'].append(income_representation_ratio)\n",
    "                type_metric_vals['race_representation_ratio'].append(race_representation_ratio)\n",
    "                \n",
    "        for k in type_metric_vals:\n",
    "            if k in ['income_corr_gap', 'race_corr_gap', 'income_ece_gap', 'race_ece_gap']:\n",
    "                for i in range(3):\n",
    "                    metric_vals[k][i].append(type_metric_vals[k][i])\n",
    "            else:\n",
    "                metric_vals[k].append(type_metric_vals[k])\n",
    "    \n",
    "    for k in metric_vals:\n",
    "        with warnings.catch_warnings():\n",
    "            # calculate mean and 95% confidence interval over correlations\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            if k in ['income_corr_gap', 'race_corr_gap', 'income_ece_gap', 'race_ece_gap']:\n",
    "                for i in range(3):\n",
    "                    metric_vals_k = np.array(metric_vals[k][i])\n",
    "                    filtered_metric_vals = metric_vals_k[~np.isnan(metric_vals_k).any(axis=1)]\n",
    "                    mean_for_each_job = filtered_metric_vals.mean(axis=0)\n",
    "                    mean_overall = filtered_metric_vals.mean()\n",
    "                    se_across_jobs = np.std(mean_for_each_job) / np.sqrt(len(mean_for_each_job) - 1)\n",
    "                    print(f'Model: {m}, Group number: {i}, {k}: {mean_overall:.4f} \\pm {1.96 * se_across_jobs:.4f}')\n",
    "            else:\n",
    "                metric_vals_k = np.array(metric_vals[k])\n",
    "                filtered_metric_vals = metric_vals_k[~np.isnan(metric_vals_k).any(axis=1)]\n",
    "                mean_for_each_job = filtered_metric_vals.mean(axis=0)\n",
    "                mean_overall = filtered_metric_vals.mean()\n",
    "                se_across_jobs = np.std(mean_for_each_job) / np.sqrt(len(mean_for_each_job) - 1)\n",
    "                print('Model: {}, {}: {:.4f} \\pm {:.4f}'.format(m, k, mean_overall, 1.96 * se_across_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1aa767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

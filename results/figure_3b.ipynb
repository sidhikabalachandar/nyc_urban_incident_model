{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot of corr(pred rating, true rating) across hold out percentages for subsampled data \n",
    "# run on full model, ratings-only model, and reports-only model \n",
    "# with semi-synthetic data for types with observed ratings\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Set the font used for math expressions to LaTeX\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "base_file = '/share/garg/311_data/sb2377/clean_codebase/three_year_base.csv'\n",
    "type_rating_observed_base_file = '/share/garg/311_data/sb2377/clean_codebase/three_year_type_rating_observed_base.csv'\n",
    "results_dir = '/share/garg/311_data/sb2377/results'\n",
    "\n",
    "# user specified arguments\n",
    "types = {'Rodent': 'RodentDOHMH'}\n",
    "holdout_pcts = {'100':100,\n",
    "                '500':500,\n",
    "                '1k':1000,\n",
    "                '10k':10000,\n",
    "                '100k':100000,\n",
    "                'full':1000000}\n",
    "models = {'Full model': {'Rodent':{'100':{'job_ids':[10 * i + 6700 for i in range(13)]},\n",
    "                                   '500':{'job_ids':[10 * i + 6702 for i in range(13)]},\n",
    "                                   '1k':{'job_ids':[10 * i + 6704 for i in range(13)]},\n",
    "                                   '10k':{'job_ids':[10 * i + 6706 for i in range(13)]},\n",
    "                                   '100k':{'job_ids':[10 * i + 6708 for i in range(13)]},\n",
    "                                   'full':{'job_ids':[3000] + [i * 3 + 3005 for i in range(12)]}}},\n",
    "          'Ratings-only model': {'Rodent':{'100':{'job_ids':[10 * i + 6701 for i in range(13)]},\n",
    "                                           '500':{'job_ids':[10 * i + 6703 for i in range(13)]},\n",
    "                                           '1k':{'job_ids':[10 * i + 6705 for i in range(13)]},\n",
    "                                           '10k':{'job_ids':[10 * i + 6707 for i in range(13)]},\n",
    "                                           '100k':{'job_ids':[10 * i + 6709 for i in range(13)]},\n",
    "                                           'full':{'job_ids':[3002] + [i * 3 + 3007 for i in range(12)]}}}}\n",
    "epoch = '59'\n",
    "\n",
    "# plotting parameters\n",
    "figsize=(3.25, 1)\n",
    "save_path = \"/home/sb2377/gnn_crowdsourced_model/figures/real_ratings_subsampled.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "base_df = pd.read_csv(base_file)\n",
    "type_rating_observed_base_df = pd.read_csv(type_rating_observed_base_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get type indices\n",
    "# for df with all types\n",
    "type_df = base_df[['typeagency', 'type_idxs']].drop_duplicates()\n",
    "indices = {}\n",
    "for type_name, type_id in types.items():\n",
    "    idx = type_df[type_df['typeagency'] == type_id]['type_idxs'].iloc[0]\n",
    "    indices[type_name] = idx\n",
    "\n",
    "# for df with only types with observed ratings\n",
    "type_df = type_rating_observed_base_df[['typeagency', 'type_idxs']].drop_duplicates()\n",
    "type_rating_observed_indices = {}\n",
    "for type_name, type_id in types.items():\n",
    "    idx = type_df[type_df['typeagency'] == type_id]['type_idxs'].iloc[0]\n",
    "    type_rating_observed_indices[type_name] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model Rodent: checkpoint files done = 78\n",
      "Full model Rodent: results files done = 78\n",
      "Ratings-only model Rodent: checkpoint files done = 78\n",
      "Ratings-only model Rodent: results files done = 78\n"
     ]
    }
   ],
   "source": [
    "# get predicted ratings for all jobs\n",
    "checkpoint_file = '{}/job{}/model-epoch={}.ckpt'\n",
    "results_file = '{}/job{}/epoch={}_test.pkl'\n",
    "checkpoint_counters = {}\n",
    "results_counters = {}\n",
    "for m in models:\n",
    "    checkpoint_counters[m] = {}\n",
    "    results_counters[m] = {}\n",
    "    for t in types:\n",
    "        checkpoint_counters[m][t] = 0\n",
    "        results_counters[m][t] = 0\n",
    "dfs = {}\n",
    "for m in models:\n",
    "    dfs[m] = {}\n",
    "    for t in types:\n",
    "        dfs[m][t] = {}\n",
    "        for hold_out_pct in holdout_pcts:\n",
    "            dfs[m][t][hold_out_pct] = []\n",
    "\n",
    "for m in models:\n",
    "    for t in types:\n",
    "        for hold_out_pct in holdout_pcts:\n",
    "            for job_idx in models[m][t][hold_out_pct]['job_ids']:\n",
    "                if os.path.exists(checkpoint_file.format(results_dir, job_idx, epoch)):\n",
    "                    checkpoint_counters[m][t] += 1\n",
    "                if os.path.exists(results_file.format(results_dir, job_idx, epoch)):\n",
    "                    results_counters[m][t] += 1\n",
    "                    with open(results_file.format(results_dir, job_idx, epoch), 'rb') as file:\n",
    "                        pred_rating, true_rating, mask, node_embedding, type_embedding, node_idxs, type_idxs, demographics, pred_pt, true_t = pickle.load(file)\n",
    "                    \n",
    "                    df = pd.DataFrame()\n",
    "                    df['pred_rating'] = pred_rating\n",
    "                    df['true_rating'] = true_rating\n",
    "                    df['node_idxs'] = node_idxs\n",
    "                    df['type_idxs'] = type_idxs\n",
    "                    df['pred_pt'] = pred_pt\n",
    "                    df['true_t'] = true_t\n",
    "                    df['mask'] = mask\n",
    "                    if m == 'Full model':\n",
    "                        type_df = df[df['type_idxs'] == indices[t]]\n",
    "                    else:\n",
    "                        type_df = df[df['type_idxs'] == type_rating_observed_indices[t]]\n",
    "\n",
    "                    dfs[m][t][hold_out_pct].append(type_df)\n",
    "                else:\n",
    "                    dfs[m][t][hold_out_pct].append([])\n",
    "\n",
    "for m in models:\n",
    "    for t in types:\n",
    "        print('{} {}: checkpoint files done = {}'.format(m, t, checkpoint_counters[m][t]))\n",
    "        print('{} {}: results files done = {}'.format(m, t, results_counters[m][t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure\n",
    "fig, ax = plt.subplots(len(types), 1, figsize=figsize)\n",
    "\n",
    "# first get correlations for all models, types, and hold out percentages\n",
    "corrs = {}\n",
    "for m in models:\n",
    "    corrs[m] = {}\n",
    "    for t in types:\n",
    "        corrs[m][t] = {}\n",
    "        for hold_out_pct in holdout_pcts:\n",
    "            corrs[m][t][hold_out_pct] = []\n",
    "            for observed_df in dfs[m][t][hold_out_pct]:\n",
    "                if len(observed_df) > 0:\n",
    "                    # Filter and group the data\n",
    "                    if m == 'Full model':\n",
    "                        observed_test_type_df = observed_df[observed_df['type_idxs'] == indices[t]]\n",
    "                    else:\n",
    "                        observed_test_type_df = observed_df[observed_df['type_idxs'] == type_rating_observed_indices[t]]\n",
    "                    node_df = observed_test_type_df.groupby(['node_idxs', 'type_idxs']).mean().reset_index()\n",
    "                    corr = pearsonr(node_df['pred_rating'], node_df['true_rating'])[0]\n",
    "                    corrs[m][t][hold_out_pct].append(corr)\n",
    "                else:\n",
    "                    corrs[m][t][hold_out_pct].append(np.nan)\n",
    "\n",
    "# pre process mean and stderr across hold out percentages for each model x type pair\n",
    "plot_values = {}\n",
    "for m in models:\n",
    "    plot_values[m] = {}\n",
    "    for t in types:\n",
    "        corr_set = np.array([corrs[m][t][hold_out_pct] for hold_out_pct in holdout_pcts])\n",
    "        corr_set_mean = np.nanmean(corr_set, axis=1)\n",
    "        corr_set_stderr = 1.96 * np.nanstd(corr_set, axis=1) / (np.count_nonzero(~np.isnan(corr_set), axis=1) - 1)\n",
    "        plot_values[m][t] = {'mean': corr_set_mean, 'stderr': corr_set_stderr}\n",
    "        print(m, corr_set_mean)\n",
    "\n",
    "# make line plot\n",
    "for i, m in enumerate(models):\n",
    "    for j, t in enumerate(types):\n",
    "        plt.errorbar(np.log10(np.array(list((holdout_pcts.values()))))[:-1], np.array(plot_values[m][t]['mean'])[:-1], yerr=plot_values[m][t]['stderr'][:-1], fmt='-o', capsize=5, color='C{}'.format(i), label=m)\n",
    "        plt.errorbar(np.log10(np.array(list((holdout_pcts.values()))))[-1:], np.array(plot_values[m][t]['mean'])[-1:], yerr=plot_values[m][t]['stderr'][-1:], fmt='-o', capsize=5, color='C{}'.format(i))\n",
    "        plt.ylim([min(plot_values['Ratings-only model'][t]['mean'] - plot_values['Ratings-only model'][t]['stderr']) - 0.05, \n",
    "                        max(plot_values['Full model'][t]['mean'] - plot_values['Full model'][t]['stderr']) + 0.1])  # Adjust margins\n",
    "        plt.xticks([2, 3, 4, 5, 6], ['10^2', '10^3', '10^4', '10^5', 'full'])\n",
    "        plt.text(5.5, 0.02, '//', ha='center', va='top', fontsize=10)\n",
    "            \n",
    "        plt.ylabel('Correlation of\\npredicted ratings', fontsize=12)\n",
    "    \n",
    "sns.despine()\n",
    "\n",
    "plt.xlabel('# rodent ratings observed', fontsize=12)\n",
    "plt.legend(fontsize=12, loc='lower center', bbox_to_anchor=(0.5, 1.07))\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_gnn)",
   "language": "python",
   "name": "conda_gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
